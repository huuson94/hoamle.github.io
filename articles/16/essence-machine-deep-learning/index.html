<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Essence of Machine Learning (and Deep Learning)</title>
  <meta name="description" content="">

  <!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not-->
  
    <link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'>
  
  
  <!-- Load up MathJax script if needed ... specify in /_data/options.yml file-->
  
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  

  <link rel="stylesheet" type="text/css" href="/css/tufte.css">
  <!-- <link rel="stylesheet" type="text/css" href="/css/print.css" media="print"> -->

  <link rel="canonical" href="http://hoamle.github.io/articles/16/essence-machine-deep-learning">

  <link rel="alternate" type="application/rss+xml" title="Hoa M. Le's Personal site" href="http://hoamle.github.io/feed.xml" />
</head>

  <body>
    <!--- Header and nav template site-wide -->
<header>
    <nav class="group">
    	<!-- for badge -->
<!-- 	<a href="/"><img class="badge" src="/assets/img/badge_1.png" alt="CH"></a>
 -->	
 		
 		
		
  	
		
		    
		      <a href="/css/print.css"></a>
		    
	    
  	
		
  	
		
		    
		      <a href="/index.html">about</a>
		    
	    
  	
		
		    
		      <a href="/blog/index.html">blog</a>
		    
	    
  	
		
		    
		      <a href="/project/index.html">projects & publications</a>
		    
	    
  	
		
		    
		      <a href="/talk/index.html">talks & tutorials</a>
		    
	    
  	
	</nav>
</header>


    <article class="group">
      <h1>Essence of Machine Learning (and Deep Learning)</h1>
<p class="subtitle">October 1, 2016</p>

<p>Preliminary course for new members at DSLab-HUST. Pre-requisite for courses in <em>Topic models</em> and (supervised) <em>Deep neural networks</em>.</p>

<p>This short course aims to introduce new starters to the field of <em>Machine Learning</em> (ML) with a principled approach, so that ones can understand the motivation and intuition behind ML (and eventually <em>Deep Learning</em> - DL) concepts,  later learn advanced materials *efficiently*, catch up with recent advances in the field, and be ready to do ML research and/or industrial applications.</p>

<p><em>Intended learning objectives</em>: (i) understand and know what constitute of the high-level ML concepts below; (ii) be able to navigate new ML concepts in <a href="#map">the Map of Machine Learning</a>; (iii) - <em>optionally</em> - articulate the math behind each model or concept, and implement the ML models/algorithms covered in the course properly (expected from students who do the homework and <a href="#study">“Study-group” sessions</a>)</p>

<h2 id="a-namemapcore-ml-conceptsa"><a name="map">Core ML concepts</a></h2>
<p><label for="mn-map" class="margin-toggle"> ⊕</label><input type="checkbox" id="mn-map" class="margin-toggle" /><span class="marginnote">TODO draw the Map </span> We will cover the following concepts. <font color="red">Note</font>: if not stated otherwise, concepts in <strong><em>bold italic</em></strong> are covered in the prelim course. <a href="#notes">Course notes</a> is be expected in respective blog posts.</p>

<h3 id="build-a-machine-learning-model">Build a Machine Learning model</h3>
<p><strong>Design principle</strong>: Model <label for="sn-model" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-model" class="margin-toggle" /><span class="sidenote"><em>“Model is a simplification of reality”</em>. Formulate real-life problems as <strong><em>parametric models</em></strong> (non-parametric models/methods are not covered in this training course series) </span> = Model “Structure”<label for="sn-structure" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-structure" class="margin-toggle" /><span class="sidenote">Relationships between model elements: data, parameters, and hyperparameters.  Relationships can either be <em>deterministic</em> or <em>stochastic</em>, and are visualized graphically by <strong><em>graphical models</em></strong>. </span> + Learning Framework<label for="sn-framework" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-framework" class="margin-toggle" /><span class="sidenote">Examples: <strong><em>probabilistic modelling</em></strong>, <em>metric learning</em> (not covered in prelim course) </span></p>

<p><strong><em>Learning task</em></strong> and <strong><em>Inference task(s)</em></strong><label for="sn-estimate" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-estimate" class="margin-toggle" /><span class="sidenote">Find/compute <em>unknown</em> parameter and/or <strong><em>latent variable</em></strong> estimates (<em>learning task</em>) of the model, and other quantities of interest (<em>inference tasks</em>), e.g. predictive outcomes, posterior distribution of model parameters, etc. </span></p>

<h3 id="evaluate-performance-of-a-model">Evaluate performance of a model</h3>

<p><strong><em>Assessment metrics</em></strong>: which metrics to measure the performance?</p>

<p><strong><em>Analyze results</em></strong>: are the results meaningful<label for="sn-meaningful" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-meaningful" class="margin-toggle" /><span class="sidenote">in terms of <em>statistical</em> significance, interpretability, or interesting observation </span>  and legitimate<label for="sn-analyze" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-analyze" class="margin-toggle" /><span class="sidenote">We will touch on <strong><em>experimental design</em></strong> </span>?</p>

<h3 id="regularize-a-model">Regularize a model</h3>
<p><code class="highlighter-rouge">&gt;</code> to fight <strong><em>overfitting</em></strong> issue. Example approaches: weight penalty, <strong><em>Bayesian modelling</em></strong><label for="sn-bayes" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-bayes" class="margin-toggle" /><span class="sidenote">We will also see Bayesian modelling, and eventually <em>Bayesian inference</em>, when building <strong><em>generative models</em></strong> for clustering problem </span>, Early-stopping, Data augmentation, Dropout; or</p>

<p><code class="highlighter-rouge">&gt;</code> to achieve some interpretability via <em>sparsity</em><label for="sn-sparse" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-sparse" class="margin-toggle" /><span class="sidenote">covered in Topic Models course </span>; or</p>

<p><code class="highlighter-rouge">&gt;</code> to achieve <a href="https://en.wikipedia.org/wiki/Regularization*(mathematics)">other objectives</a>.</p>

<h3 id="optimize-for-more-performance">Optimize for more performance</h3>
<p><strong><em>Model selection</em></strong> and <em>Model ensemble</em> techniques</p>

<h2 id="references">References</h2>
<p>Course content is partially taken from the following sources:</p>

<blockquote>
  <p>Christopher Bishop’s <a href="https://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738">Pattern Recognition and Machine Learning</a> &lt;- Comprehensive textbook on Probabilistic modelling with focus on Bayesian methods.</p>
</blockquote>

<blockquote>
  <p>Andrew Ng’s Machine Learning class (<a href="https://www.coursera.org/learn/machine-learning">Coursera</a> or <a href="http://cs229.stanford.edu/">CS229</a>) &lt;- Practical introduction to Machine Learning and common learning algorithms.</p>
</blockquote>

<blockquote>
  <p>Stanford Univ’s <a href="http://cs231n.stanford.edu/">CS231n - ConvNet for Visual Recognition</a> &lt;- Practical course on Deep neural networks (DNN) with the context of computer vision problems.</p>
</blockquote>

<blockquote>
  <p><a href="http://shakirm.com/?section=3">Shakir Mohamed</a>’s tutorial on Deep Generative Models in Deep Learning Summer School, 2016 &lt;- Terrific summary of modelling principles and categorization of model classes. Also introduce recent advances in marrying Probabilistic modelling with DNN.</p>
</blockquote>

<h2 id="a-namestudycourse-logisticsa"><a name="study">Course logistics</a></h2>
<p>2 sessions/week: 1x “<strong>Lecture</strong>” session + 1x optional “<strong>Study-group</strong>” session.<br />
<code class="highlighter-rouge">&gt;</code> <strong><em>Lectures</em></strong> are meant to lead you in the right direction — just to get your started. They are <strong>not</strong> meant to tell you <em>everything</em> in <em>every details</em>.</p>

<blockquote>
  <p>Therefore you should utilize the reference reading materials, online resources for missing details <em>&lt;- (the role of <strong>self-study</strong>)</em></p>
</blockquote>

<p><code class="highlighter-rouge">&gt;</code> It should be reckoned that we do not know everything (in <em>many cases</em>, we don’t even know what we don’t know), so utilize the course instructors, the Teaching Assistant - TAs, your classmates for further support/discussion/…  <em>&lt;- (the importance of <strong>Study-group</strong>)</em></p>

<blockquote>
  <p><strong>Tip</strong>: Use comment sections in <em>relevant</em> blog posts to reach this course instructor(s). The advantage: other audience (e.g. TAs, classmates, passing-by experts) can also contribute to your questions or discussion. Use email as secondary option.</p>
</blockquote>

<h2 id="a-namenotescourse-notesa"><a name="notes">Course notes</a></h2>
<p>WEEK 1 - <a href="https://raw.githubusercontent.com/hoamle/essence_ml/e788aef7617fed6911bcfd710ebbccd8ed34eae6/essence_ml.pdf">Introduction</a> (with <a href="https://raw.githubusercontent.com/hoamle/essence_ml/e788aef7617fed6911bcfd710ebbccd8ed34eae6/essence_ml_with_notes.pdf">Notes</a>) &amp; <a href="/articles/17/primer-on-building-ml-solutions">Primer on Building a Machine Learning solution</a></p>

<p>WEEK 2 - Principles of Modelling: Model structure, Learning framework</p>

<p>WEEK 3 - Principles of Modelling: Regularization, “Deep” Model structure</p>

<p>WEEK 4 - Bayesian inference</p>

<p>WEEK 5 - TBE</p>



<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/

var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//hoamle.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>




    </article>
    <span class="print-footer">Essence of Machine Learning (and Deep Learning) - October 1, 2016 - Hoa M. Le</span>
    <footer>
  <hr class="slender">
  <ul class="footer-links">
    <li><a href="mailto:hoamle@outlook.com"><span class="icon-mail"></span></a></li>    
    
      <li>
        <a href="//linkedin.com/in/hoamle"><span class="icon-googleplus"></span></a>
      </li>
    
      <li>
        <a href="//github.com/hoamle"><span class="icon-github"></span></a>
      </li>
    
      <li>
        <a href="/feed.xml"><span class="icon-feed"></span></a>
      </li>
      
  </ul>
<div class="credits">
<span>&copy; 2017 &nbsp;&nbsp;HOA M. LE</span></br> <br>
<span>This site is created with the <a href="//github.com/clayh53/tufte-jekyll">Tufte theme for  </a> <a href="//jekyllrb.com">Jekyll</a>.</span>
</div>  
</footer>
  </body>
</html>
